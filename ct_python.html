<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>NAME THAT SHOWS IN THE TAB ABOVE</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/NeuroNestLogo.png" alt="NeuroNest Logo" /></span><span class="title">NeuroNest</span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="resource_menu.html">Resources</a></li>
							<li><a href="https://sopkoc.wixsite.com/neuronest/forum">Ask a Question</a></li>
							<li><a href="https://sopkoc.wixsite.com/neuronest/about">About NeuroNest</a></li>
							<li><a href="https://sopkoc.wixsite.com/neuronest/contact">Contact</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Welcome to the NeuroNest Tutorial on CT Imaging Classification using Artificial Neural Networks!</h1>
							<span class="image main"><img src="images/pic13.jpg" alt="" /></span>
							<h2 id="tutorial-overview-">Tutorial Overview:</h2>
								<p><em>Tutorial time</em>: approximately 70 min</p>
								<p>In this tutorial, our objective is to build a neural network using PyTorch to classify CT brain images as either normal or having a hemorrhage. We will cover the entire process from data preprocessing to model evaluation.</p>
								<p>If you prefer an interactive tutorial, please see our <a href="https://colab.research.google.com/drive/1YQe8rqhup-_ihQJeAmzNhdOqP6ZTHiya?usp=sharing#scrollTo=-fYsSG8v71NH">Google Colab version</a>.</p>
							<h3 id="objectives-">Objectives:</h3>
								<ol>
								<li><strong>Introduction and Setup</strong></li>
								<li><strong>Importing Required Libraries</strong></li>
								<li><strong>Downloading the Data</strong></li>
								<li><strong>Loading the Dataset</strong></li>
								<li><strong>Exploratory Data Analysis (EDA)</strong></li>
								<li><strong>Data Preprocessing</strong></li>
								<li><strong>Splitting the Dataset</strong></li>
								<li><strong>Building the Neural Network Model</strong></li>
								<li><strong>Training and Evaluating the Model</strong></li>
								<li><strong>Visualizing Model Performance</strong></li>
								</ol>			
								<p><strong>Let's get started!</strong></p>
							<h2 id="1-introduction-and-setup">1. Introduction and Setup</h2>
								<p>CT imaging, or Computed Tomography imaging, uses X-rays to create detailed pictures of the inside of the body. It is crucial in medical diagnostics for detecting conditions such as tumors, fractures, and hemorrhages. <a href="ct_info.html">Read more about CT neuroimaging here.</a></p>
								<p>In this tutorial, we will cover several fundamental concepts that are essential for processing and visualizing CT brain images in Python, as well as building a neural network. We will walk through each step to classify CT brain images as either normal (labeled 0) or having a hemorrhage (labeled 1). By the end of this tutorial, you should have a solid understanding of how to preprocess the data, build, and evaluate a neural network model using PyTorch.</p>
								<p>For more information about how to install, access, or code in Python, visit <a href="python_data.html">NeuroNest's Python Tutorial</a>.</p>
							<h2 id="2-importing-required-libraries">2. Importing Required Libraries</h3>
								<p>To build our neural network, we&#39;ll need several Python and PyTorch libraries. These libraries will help with data manipulation, model building, and visualization.</p>
<pre><code><strong># Import essential libraries for building a Neural Network using Pytorch</strong>
<p>import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import shutil
import random
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix</p>
<p><strong># Additional libraries for data handling and visualization</strong>
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
from PIL import Image</p>
</code></pre>
							<h2>3. Downloading the Data</h2>
							<p>We will use a CT Brain Imaging dataset from Kaggle. Either download directly from Kaggle at <a href="https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage">https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage</a> or run the code below to use the Kaggle API to automatically download and extract the dataset.</p>
<pre><code><p>IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK.
	NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE&#39;S PYTHON ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR NOTEBOOK.</p>
<p>import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil
	
CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = &#39;head-ct-hemorrhage:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F71215%2F152137%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240807%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240807T171722Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4cfcf43a51e3ca0216a816401c6a9ead19272a4e62a33ee3ae3d4315eb4f6eb1822cba8fc13ac00113bbc390a84a3cda5ce0b6faddb2740af90e5cb916dfc6fe81f546e55803c4f74b75d95db4b64a2e0cc77f6820c062c5ccfca7a8404cd851eb66a7c89fa26a97ebf23b82ce8c1141d9ee2b2f1e48f297d299efd306776e3fb6bb49381126c0f7c5a9c26f26c2020efcea9f05b4a5625d2bcbf1f2c54c542692184d2140118c7e988c0e18734f5a128891c2845aa2814067cb6253c95309bcfcc255dc0add78794f789ff063f7f46b291c48f3161789aea3de080cf09e2f54631cbc58d788711f19cb76dab1b9424d58b31825e7f4becac5ed4ed8e2ff389a&#39;</p>
<p>KAGGLE_INPUT_PATH=&#39;/kaggle/input&#39;
KAGGLE_WORKING_PATH=&#39;/kaggle/working&#39;
KAGGLE_SYMLINK=&#39;kaggle&#39;

!umount /kaggle/input/ 2&gt; /dev/null
shutil.rmtree(&#39;/kaggle/input&#39;, ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)
	
try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join(&quot;..&quot;, &#39;input&#39;), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join(&quot;..&quot;, &#39;working&#39;), target_is_directory=True)
except FileExistsError:
  pass
	
for data_source_mapping in DATA_SOURCE_MAPPING.split(&#39;,&#39;):
    directory, download_url_encoded = data_source_mapping.split(&#39;:&#39;)
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
	with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
	    total_length = fileres.headers[&#39;content-length&#39;]
	    print(f&#39;Downloading {directory}, {total_length} bytes compressed&#39;)
	    dl = 0
	    data = fileres.read(CHUNK_SIZE)
	    while len(data) &gt; 0:
		dl += len(data)
		tfile.write(data)
		done = int(50 <em> dl / int(total_length))
		sys.stdout.write(f&quot;\r[{&#39;=&#39; </em> done}{&#39; &#39; * (50-done)}] {dl} bytes downloaded&quot;)
		sys.stdout.flush()
		data = fileres.read(CHUNK_SIZE)
	    if filename.endswith(&#39;.zip&#39;):
	      with ZipFile(tfile) as zfile:
		zfile.extractall(destination_path)
	    else:
	      with tarfile.open(tfile.name) as tarfile:
		tarfile.extractall(destination_path)
	    print(f&#39;\nDownloaded and uncompressed: {directory}&#39;)
    except HTTPError as e:
	print(f&#39;Failed to load (likely expired) {download_url} to path {destination_path}&#39;)
	continue
    except OSError as e:
	print(f&#39;Failed to load {download_url} to path {destination_path}&#39;)
	continue
	
print(&#39;Data source import complete.&#39;)
</code></pre>						
							<p><h2>4. Loading the Dataset</h2>
							To begin analyzing our dataset, we need to load the images and their corresponding labels into Python. We can achieve this using libraries like Pandas for handling the labels and PIL (Python Imaging Library) for loading the images.</p>
							<p><strong>4.1. Loading the Labels.</strong>
								First, weâ€™ll load the labels from a CSV file and apply necessary corrections.</p>
<pre><code># Load the labels
labels = pd.read_csv('/kaggle/input/head-ct-hemorrhage/labels.csv')

# Rename column if necessary (remove extra spaces)
labels.rename(columns={' hemorrhage': 'hemorrhage'}, inplace=True)

# Convert 'id' column to integer, then format as string with .png extension
labels['id'] = labels['id'].astype(int)
labels['id'] = labels['id'].apply(lambda x: str('%03d' % x) + ".png")
</code></pre>
							<p>The <code>labels.head()</code>` function outputs the first few rows of the labels DataFrame, which looks like this:</p>
<pre><code>
# Display the first few rows to verify
print(labels.head())

# List unique classes in the 'hemorrhage' column
classes = list(labels['hemorrhage'].unique())
print("Classes:", classes)
</code></pre>
							<p>This DataFrame has two columns:
								id: A unique identifier for each image.
								hemorrhage: The label indicating whether the image shows a hemorrhage (1) or is normal (0).</p>
							<p><strong>4.2 Loading and Displaying Sample Images.</strong>
								Next, we'll load some sample images using PIL and display them along with their labels.</p>
<pre><code>from PIL import Image
import matplotlib.pyplot as plt

# Function to display images in a grid
def display_images_grid(image_paths, labels):
    num_images = len(image_paths)
    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))

    if num_images == 1:
        axes = [axes]  # Ensure axes is iterable if there's only one image

    for ax, image_path, label in zip(axes, image_paths, labels):
        img = Image.open(image_path)
        ax.imshow(img, cmap='gray')
        ax.set_title(f'Label: {label}')
        ax.axis('off')

    plt.show()

# Ensure we include at least one image from each class
class_0_image = labels[labels['hemorrhage'] == 0].sample(1)
class_1_image = labels[labels['hemorrhage'] == 1].sample(1)

# Combine samples from both classes and a few additional random samples
additional_images = labels.sample(3)  # Add more samples for variety
selected_images = pd.concat([class_0_image, class_1_image, additional_images])

# Construct image paths and labels
image_paths = [f'/kaggle/input/head-ct-hemorrhage/head_ct/head_ct/{row["id"]}' for _, row in selected_images.iterrows()]
image_labels = selected_images['hemorrhage'].tolist()

# Display the images side by side
display_images_grid(image_paths, image_labels)
</code></pre>
							<img src="images/ct_python_1.png" alt="images output" style="width: 25%;"> 
							<p>Did you notice that images dont have the same size? We will get into that shortly.</p>
							<h2>5. Exploratory Data Analysis (EDA)</h2>
							<p>Before performing any kind of experimentation or analysis, it's crucial to understand the dataset. Exploratory Data Analysis (EDA) helps us get insights into the data, detect any anomalies, and understand its structure. In this step, we'll perform basic statistics, visualize the distribution of labels, and display some sample images to gain a better understanding of our dataset.</p>
							<p><strong>Basic Statistics:</strong> Let's start by examining some basic statistics of our dataset, such as the number of samples and the distribution of labels.</p>
<pre><code>
# Basic statistics
num_samples = len(labels)
label_distribution = labels['hemorrhage'].value_counts()

print(f'Total number of samples: {num_samples}')
print('Distribution of labels:')
print(label_distribution)
</code></pre>
							<p>Here we observe that our dataset is perfectly balanced, with an equal number of images for both classes: hemorrhage and normal. This balance is important for training our neural network, as it ensures that the model has an equal opportunity to learn from both types of images, which can help improve its performance and reduce bias.</p>
							<p><strong>Checking Image Size:</strong>Since we will be dealing with image data, It's important to verify that all images in our dataset have the same dimensions. Inconsistent image sizes can cause issues when training a model. Let's check the sizes of all images.
								The code below checks the width and height of each image and gives us a summary of these sizes. If the images vary too much, we may need to resize them to ensure consistency before training our model.</p>
<pre><code>
# Function to get image sizes
def get_image_sizes(image_folder):
    sizes = []
    for filename in os.listdir(image_folder):
        if filename.endswith(".png"):
            with Image.open(os.path.join(image_folder, filename)) as img:
                sizes.append(img.size)
    return sizes

# Get image sizes
image_folder = '/kaggle/input/head-ct-hemorrhage/head_ct/head_ct/'
sizes = get_image_sizes(image_folder)
size_df = pd.DataFrame(sizes, columns=['Width', 'Height'])
print(size_df.describe())
</code></pre>
							<p>From the table, we observe the following about our image dimensions:</p>
							<ul>
							<li><strong>Width:</strong> The width of the images ranges from 134 pixels to 821 pixels, with an average width of approximately 355 pixels.</li>
							<li><strong>Height:</strong> The height of the images ranges from 135 pixels to 957 pixels, with an average height of about 434 pixels.</li>
							</ul>
							<p>This indicates that our images vary significantly in size. Most images are around 345x435 pixels, but there is a wide range in dimensions. To ensure consistency and avoid problems during model training, we should resize all images to a standard size. This will help the neural network process the images more effectively and uniformly.</p>
							<p>Before we move forward with resizing, letâ€™s perform one last check to see if there are any corrupt images in our dataset.</p>
							<p><strong>Checking for Corrupt or Empty Images:</strong></p>
<pre><code>
def check_image_integrity(image_folder):
    corrupt_images = []
    for filename in os.listdir(image_folder):
        if filename.endswith(".png"):
            try:
                with Image.open(os.path.join(image_folder, filename)) as img:
                    img.verify()  # Verify image integrity
            except (IOError, SyntaxError) as e:
                corrupt_images.append(filename)
    return corrupt_images

# Check for corrupt images
corrupt_images = check_image_integrity(image_folder)
print(f'Number of corrupt images: {len(corrupt_images)}')
if corrupt_images:
    print('Corrupt images found:', corrupt_images)
</code></pre>
							<p>Fantastic! We have no corrupt images, let now proceed forward with resizing and other preprocessing steps</p>
						</div>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<section>
								<h2>Get in touch</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<input type="text" name="name" id="name" placeholder="Name" />
										</div>
										<div class="field half">
											<input type="email" name="email" id="email" placeholder="Email" />
										</div>
										<div class="field">
											<textarea name="message" id="message" placeholder="Message"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send" class="primary" /></li>
									</ul>
								</form>
							</section>
							<section>
								<h2>Follow</h2>
								<ul class="icons">
									<li><a href="#" class="icon brands style2 fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands style2 fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands style2 fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands style2 fa-dribbble"><span class="label">Dribbble</span></a></li>
									<li><a href="#" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
									<li><a href="#" class="icon brands style2 fa-500px"><span class="label">500px</span></a></li>
									<li><a href="#" class="icon solid style2 fa-phone"><span class="label">Phone</span></a></li>
									<li><a href="#" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								</ul>
							</section>
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
