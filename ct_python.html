<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>NAME THAT SHOWS IN THE TAB ABOVE</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/NeuroNestLogo.png" alt="NeuroNest Logo" /></span><span class="title">NeuroNest</span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="resource_menu.html">Resources</a></li>
							<li><a href="https://sopkoc.wixsite.com/neuronest/forum">Ask a Question</a></li>
							<li><a href="https://sopkoc.wixsite.com/neuronest/about">About NeuroNest</a></li>
							<li><a href="https://sopkoc.wixsite.com/neuronest/contact">Contact</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Welcome to the NeuroNest Tutorial on CT Imaging Classification using Artificial Neural Networks!</h1>
							<span class="image main"><img src="images/pic13.jpg" alt="" /></span>
							<h2 id="tutorial-overview-">Tutorial Overview:</h2>
								<p><em>Tutorial time</em>: approximately 70 min</p>
								<p>In this tutorial, our objective is to build a neural network using PyTorch to classify CT brain images as either normal or having a hemorrhage. We will cover the entire process from data preprocessing to model evaluation.</p>
								<p>If you prefer an interactive tutorial, please see our <a href="https://colab.research.google.com/drive/1YQe8rqhup-_ihQJeAmzNhdOqP6ZTHiya?usp=sharing#scrollTo=-fYsSG8v71NH">Google Colab version</a>.</p>
							<h3 id="objectives-">Objectives:</h3>
								<ol>
								<li><strong>Introduction and Setup</strong></li>
								<li><strong>Importing Required Libraries</strong></li>
								<li><strong>Downloading the Data</strong></li>
								<li><strong>Loading the Dataset</strong></li>
								<li><strong>Exploratory Data Analysis (EDA)</strong></li>
								<li><strong>Data Preprocessing</strong></li>
								<li><strong>Splitting the Dataset</strong></li>
								<li><strong>Building the Neural Network Model</strong></li>
								<li><strong>Training and Evaluating the Model</strong></li>
								<li><strong>Visualizing Model Performance</strong></li>
								</ol>			
								<p><strong>Let's get started!</strong></p>
							<h2 id="1-introduction-and-setup">1. Introduction and Setup</h2>
								<p>CT imaging, or Computed Tomography imaging, uses X-rays to create detailed pictures of the inside of the body. It is crucial in medical diagnostics for detecting conditions such as tumors, fractures, and hemorrhages. <a href="ct_info.html">Read more about CT neuroimaging here.</a></p>
								<p>In this tutorial, we will cover several fundamental concepts that are essential for processing and visualizing CT brain images in Python, as well as building a neural network. We will walk through each step to classify CT brain images as either normal (labeled 0) or having a hemorrhage (labeled 1). By the end of this tutorial, you should have a solid understanding of how to preprocess the data, build, and evaluate a neural network model using PyTorch.</p>
								<p>For more information about how to install, access, or code in Python, visit <a href="python_data.html">NeuroNest's Python Tutorial</a>.</p>
							<h2 id="2-importing-required-libraries">2. Importing Required Libraries</h3>
								<p>To build our neural network, we&#39;ll need several Python and PyTorch libraries. These libraries will help with data manipulation, model building, and visualization.</p>
<pre><code><strong># Import essential libraries for building a Neural Network using Pytorch</strong>
<p>import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import shutil
import random
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix</p>
<p><strong># Additional libraries for data handling and visualization</strong>
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
from PIL import Image</p>
</code></pre>
							<h2>3. Downloading the Data</h2>
							<p>We will use a CT Brain Imaging dataset from Kaggle. Either download directly from Kaggle at <a href="https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage">https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage</a> or run the code below to use the Kaggle API to automatically download and extract the dataset.</p>
<pre><code><p>IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK.
	NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE&#39;S PYTHON ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR NOTEBOOK.</p>
<p>import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil
	
CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = &#39;head-ct-hemorrhage:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F71215%2F152137%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240807%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240807T171722Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4cfcf43a51e3ca0216a816401c6a9ead19272a4e62a33ee3ae3d4315eb4f6eb1822cba8fc13ac00113bbc390a84a3cda5ce0b6faddb2740af90e5cb916dfc6fe81f546e55803c4f74b75d95db4b64a2e0cc77f6820c062c5ccfca7a8404cd851eb66a7c89fa26a97ebf23b82ce8c1141d9ee2b2f1e48f297d299efd306776e3fb6bb49381126c0f7c5a9c26f26c2020efcea9f05b4a5625d2bcbf1f2c54c542692184d2140118c7e988c0e18734f5a128891c2845aa2814067cb6253c95309bcfcc255dc0add78794f789ff063f7f46b291c48f3161789aea3de080cf09e2f54631cbc58d788711f19cb76dab1b9424d58b31825e7f4becac5ed4ed8e2ff389a&#39;</p>
<p>KAGGLE_INPUT_PATH=&#39;/kaggle/input&#39;
KAGGLE_WORKING_PATH=&#39;/kaggle/working&#39;
KAGGLE_SYMLINK=&#39;kaggle&#39;

!umount /kaggle/input/ 2&gt; /dev/null
shutil.rmtree(&#39;/kaggle/input&#39;, ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)
	
try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join(&quot;..&quot;, &#39;input&#39;), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join(&quot;..&quot;, &#39;working&#39;), target_is_directory=True)
except FileExistsError:
  pass
	
for data_source_mapping in DATA_SOURCE_MAPPING.split(&#39;,&#39;):
    directory, download_url_encoded = data_source_mapping.split(&#39;:&#39;)
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
	with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
	    total_length = fileres.headers[&#39;content-length&#39;]
	    print(f&#39;Downloading {directory}, {total_length} bytes compressed&#39;)
	    dl = 0
	    data = fileres.read(CHUNK_SIZE)
	    while len(data) &gt; 0:
		dl += len(data)
		tfile.write(data)
		done = int(50 <em> dl / int(total_length))
		sys.stdout.write(f&quot;\r[{&#39;=&#39; </em> done}{&#39; &#39; * (50-done)}] {dl} bytes downloaded&quot;)
		sys.stdout.flush()
		data = fileres.read(CHUNK_SIZE)
	    if filename.endswith(&#39;.zip&#39;):
	      with ZipFile(tfile) as zfile:
		zfile.extractall(destination_path)
	    else:
	      with tarfile.open(tfile.name) as tarfile:
		tarfile.extractall(destination_path)
	    print(f&#39;\nDownloaded and uncompressed: {directory}&#39;)
    except HTTPError as e:
	print(f&#39;Failed to load (likely expired) {download_url} to path {destination_path}&#39;)
	continue
    except OSError as e:
	print(f&#39;Failed to load {download_url} to path {destination_path}&#39;)
	continue
	
print(&#39;Data source import complete.&#39;)
</code></pre>						
							<p><h2>4. Loading the Dataset</h2>
							To begin analyzing our dataset, we need to load the images and their corresponding labels into Python. We can achieve this using libraries like Pandas for handling the labels and PIL (Python Imaging Library) for loading the images.</p>
							<p><strong>4.1. Loading the Labels.</strong>
								First, we’ll load the labels from a CSV file and apply necessary corrections.</p>
<pre><code># Load the labels
labels = pd.read_csv('/kaggle/input/head-ct-hemorrhage/labels.csv')

# Rename column if necessary (remove extra spaces)
labels.rename(columns={' hemorrhage': 'hemorrhage'}, inplace=True)

# Convert 'id' column to integer, then format as string with .png extension
labels['id'] = labels['id'].astype(int)
labels['id'] = labels['id'].apply(lambda x: str('%03d' % x) + ".png")
</code></pre>
							<p>The <code>labels.head()</code>` function outputs the first few rows of the labels DataFrame, which looks like this:</p>
<pre><code>
# Display the first few rows to verify
print(labels.head())

# List unique classes in the 'hemorrhage' column
classes = list(labels['hemorrhage'].unique())
print("Classes:", classes)
</code></pre>
							<p>This DataFrame has two columns:
								id: A unique identifier for each image.
								hemorrhage: The label indicating whether the image shows a hemorrhage (1) or is normal (0).</p>
							<p><strong>4.2 Loading and Displaying Sample Images.</strong>
								Next, we'll load some sample images using PIL and display them along with their labels.</p>
<pre><code>from PIL import Image
import matplotlib.pyplot as plt

# Function to display images in a grid
def display_images_grid(image_paths, labels):
    num_images = len(image_paths)
    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))

    if num_images == 1:
        axes = [axes]  # Ensure axes is iterable if there's only one image

    for ax, image_path, label in zip(axes, image_paths, labels):
        img = Image.open(image_path)
        ax.imshow(img, cmap='gray')
        ax.set_title(f'Label: {label}')
        ax.axis('off')

    plt.show()

# Ensure we include at least one image from each class
class_0_image = labels[labels['hemorrhage'] == 0].sample(1)
class_1_image = labels[labels['hemorrhage'] == 1].sample(1)

# Combine samples from both classes and a few additional random samples
additional_images = labels.sample(3)  # Add more samples for variety
selected_images = pd.concat([class_0_image, class_1_image, additional_images])

# Construct image paths and labels
image_paths = [f'/kaggle/input/head-ct-hemorrhage/head_ct/head_ct/{row["id"]}' for _, row in selected_images.iterrows()]
image_labels = selected_images['hemorrhage'].tolist()

# Display the images side by side
display_images_grid(image_paths, image_labels)
</code></pre>
							<img src="images/ct_python_1.png" alt="images output" style="width: 25%;"> 
							<p>Did you notice that the images dont have the same size? We will get into that shortly.</p>
							<h2>5. Exploratory Data Analysis (EDA)</h2>
							<p>Before performing any kind of experimentation or analysis, it's crucial to understand the dataset. Exploratory Data Analysis (EDA) helps us get insights into the data, detect any anomalies, and understand its structure. In this step, we'll perform basic statistics, visualize the distribution of labels, and display some sample images to gain a better understanding of our dataset.</p>
							<p><strong>Basic Statistics:</strong> Let's start by examining some basic statistics of our dataset, such as the number of samples and the distribution of labels.</p>
<pre><code>
# Basic statistics
num_samples = len(labels)
label_distribution = labels['hemorrhage'].value_counts()

print(f'Total number of samples: {num_samples}')
print('Distribution of labels:')
print(label_distribution)
</code></pre>
							<p>Here we observe that our dataset is perfectly balanced, with an equal number of images for both classes: hemorrhage and normal. This balance is important for training our neural network, as it ensures that the model has an equal opportunity to learn from both types of images, which can help improve its performance and reduce bias.</p>
							<p><strong>Checking Image Size:</strong>Since we will be dealing with image data, It's important to verify that all images in our dataset have the same dimensions. Inconsistent image sizes can cause issues when training a model. Let's check the sizes of all images.
								The code below checks the width and height of each image and gives us a summary of these sizes. If the images vary too much, we may need to resize them to ensure consistency before training our model.</p>
<pre><code>
# Function to get image sizes
def get_image_sizes(image_folder):
    sizes = []
    for filename in os.listdir(image_folder):
        if filename.endswith(".png"):
            with Image.open(os.path.join(image_folder, filename)) as img:
                sizes.append(img.size)
    return sizes

# Get image sizes
image_folder = '/kaggle/input/head-ct-hemorrhage/head_ct/head_ct/'
sizes = get_image_sizes(image_folder)
size_df = pd.DataFrame(sizes, columns=['Width', 'Height'])
print(size_df.describe())
</code></pre>
							<p>From the table, we observe the following about our image dimensions:</p>
							<ul>
							<li><strong>Width:</strong> The width of the images ranges from 134 pixels to 821 pixels, with an average width of approximately 355 pixels.</li>
							<li><strong>Height:</strong> The height of the images ranges from 135 pixels to 957 pixels, with an average height of about 434 pixels.</li>
							</ul>
							<p>This indicates that our images vary significantly in size. Most images are around 345x435 pixels, but there is a wide range in dimensions. To ensure consistency and avoid problems during model training, we should resize all images to a standard size. This will help the neural network process the images more effectively and uniformly.</p>
							<p>Before we move forward with resizing, let’s perform one last check to see if there are any corrupt images in our dataset.</p>
							<p><strong>Checking for Corrupt or Empty Images:</strong></p>
<pre><code>
def check_image_integrity(image_folder):
    corrupt_images = []
    for filename in os.listdir(image_folder):
        if filename.endswith(".png"):
            try:
                with Image.open(os.path.join(image_folder, filename)) as img:
                    img.verify()  # Verify image integrity
            except (IOError, SyntaxError) as e:
                corrupt_images.append(filename)
    return corrupt_images

# Check for corrupt images
corrupt_images = check_image_integrity(image_folder)
print(f'Number of corrupt images: {len(corrupt_images)}')
if corrupt_images:
    print('Corrupt images found:', corrupt_images)
</code></pre>
							<p>Fantastic! We have no corrupt images, let now proceed forward with resizing and other preprocessing steps</p>
							<h2>6. Data Preprocessing</h2>
							<p>Before feeding our images into a neural network, we need to preprocess them to ensure they are in the right format and size. Preprocessing helps improve model performance and training efficiency. Common preprocessing steps include resizing, normalization, and data augmentation.</p>
							<p><strong>6.1 Resize Images:</strong>Previously, we observed that the sizes of images in our dataset vary widely. To ensure consistency, we resize all images to a standard size of 224x224 pixels. This size is commonly used in image processing and deep learning. We also chose 224x224 size because it offers a good balance between maintaining enough image detail and managing computational resources. Larger images would provide more detail but require more memory and processing power. On the other hand, smaller images would be easier to handle but might lose important details. By resizing our images to a uniform size, we make it easier for the neural network to process them consistently and effectively.</p>
<pre><code>
# Define the target size
target_size = (224, 224)  # Example size

def resize_images(image_folder, target_size):
    resized_folder = '/kaggle/input/head-ct-hemorrhage/resized_images/'
    os.makedirs(resized_folder, exist_ok=True)

    for filename in os.listdir(image_folder):
        if filename.endswith(".png"):
            img_path = os.path.join(image_folder, filename)
            with Image.open(img_path) as img:
                # Calculate the new size while preserving the aspect ratio
                img.thumbnail(target_size, Image.ANTIALIAS)

                # Create a new image with the target size and paste the resized image
                img_resized = Image.new("RGB", target_size, (255, 255, 255))
                img_resized.paste(img, ((target_size[0] - img.width) // 2, (target_size[1] - img.height) // 2))

                # Save the resized image
                img_resized.save(os.path.join(resized_folder, filename))

# Resize images
resize_images('/kaggle/input/head-ct-hemorrhage/head_ct/head_ct/', target_size)
</code></pre>
							<p>Now that we resized all images to 224x224 pixels, and saved them into a folder named "resized_images". Let's normalize our images.</p>
							<p><strong>6.2 Normalization:</strong> <p>You may wonder, Why do we need to normalize images? Well, Normalization scales pixel values to a standard range (typically 0 to 1). it is a crucial preprocessing step in image processing and deep learning. This process has several important benefits:</p>
							<ul>
								<li>mproves Model Training Efficiency:</li>
								<ul>
									<li>Convergence Speed: Neural networks learn more effectively when inputs are on a similar scale. Normalization helps the network converge faster during training by ensuring that all input features contribute equally to the learning process.</li>
									<li>Stable Training: Scaling inputs to a consistent range helps in stabilizing the training process, reducing the risk of gradients becoming too large or too small.</li>
								</ul>
								<li>Enhances Model Performance:</li>
								<ul>
									<li>Consistent Input Values: Normalized images provide a consistent range of values, which helps the model generalize better and improves overall performance.</li>
									<li>Prevents Bias: Without normalization, the network might learn biases based on the scale of input data, which can negatively impact the performance.</li>
								</ul>
								<li>Facilitates Use of Pretrained Models:</li>
								<ul>
									<li>Standard Practice: Many pretrained models (e.g., VGG16, ResNet) are trained with images normalized to specific mean and standard deviation values. Normalizing your images in the same way allows you to leverage these pretrained models effectively for transfer learning.</li>
								</ul>
							</ul>	
							<p>So, Does This Apply to Our Dataset?</p>
							<p>Yes, normalization is particularly relevant for our dataset of CT brain images:</p>
							<ul>
								<li>Pixel Range Consistency: The pixel values of our CT images vary widely as we saw in section 5.2. Normalizing ensures that all images are on a similar scale, which is crucial for training a neural network.</li>
								<li>Improved Training: By normalizing our images to the same scale, we help the neural network learn more effectively and make the training process more stable.</li>
							</ul>

<pre><code>
# Define normalization transform
normalize_transform = transforms.Compose([
    transforms.Resize(target_size),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Define the paths
image_folder = '/kaggle/input/head-ct-hemorrhage/resized_images/'
normalized_folder = '/kaggle/input/head-ct-hemorrhage/normalized_images/'
os.makedirs(normalized_folder, exist_ok=True)

def normalize_images(image_folder, normalized_folder):
    for filename in os.listdir(image_folder):
        if filename.endswith(".png"):
            img_path = os.path.join(image_folder, filename)
            img = Image.open(img_path)
            img_normalized = normalize_transform(img)

            # Save the normalized image
            img_normalized_pil = transforms.ToPILImage()(img_normalized)
            img_normalized_pil.save(os.path.join(normalized_folder, filename))

# Normalize all images
normalize_images(image_folder, normalized_folder)

# Display a sample normalized image and its non-normalized version side by side
def display_comparison(image_path, normalized_path):
    img = Image.open(image_path)
    img_normalized = Image.open(normalized_path)

    # Convert normalized image to tensor for display
    img_normalized_tensor = transforms.ToTensor()(img_normalized)

    # Plot the images side by side
    plt.figure(figsize=(12, 6))

    # Display non-normalized image
    plt.subplot(1, 2, 1)
    plt.imshow(img)
    plt.title('Non-Normalized Image')
    plt.axis('off')

    # Display normalized image
    plt.subplot(1, 2, 2)
    plt.imshow(img_normalized_tensor.permute(1, 2, 0))  # Convert tensor to image for visualization
    plt.title('Normalized Image')
    plt.axis('off')

    plt.show()

# Example paths for a sample image
sample_image_filename = '001.png'
display_comparison(
    os.path.join(image_folder, sample_image_filename),
    os.path.join(normalized_folder, sample_image_filename)
)
</code></pre>
							<img src="images/ct_python_2.png" alt="images output" style="width: 25%;"> 
							<p>Now, one last step remains, which is Data Augmentation.</p>

						</div>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<section>
								<h2>Get in touch</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<input type="text" name="name" id="name" placeholder="Name" />
										</div>
										<div class="field half">
											<input type="email" name="email" id="email" placeholder="Email" />
										</div>
										<div class="field">
											<textarea name="message" id="message" placeholder="Message"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send" class="primary" /></li>
									</ul>
								</form>
							</section>
							<section>
								<h2>Follow</h2>
								<ul class="icons">
									<li><a href="#" class="icon brands style2 fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands style2 fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands style2 fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands style2 fa-dribbble"><span class="label">Dribbble</span></a></li>
									<li><a href="#" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
									<li><a href="#" class="icon brands style2 fa-500px"><span class="label">500px</span></a></li>
									<li><a href="#" class="icon solid style2 fa-phone"><span class="label">Phone</span></a></li>
									<li><a href="#" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								</ul>
							</section>
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
